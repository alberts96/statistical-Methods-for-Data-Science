demo()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(stm)
install.packages("stm")
library(stm)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gutenbergr)
titles <- c("Twenty Thousand Leagues under the Sea",
"The War of the Worlds",
"Pride and Prejudice",
"Great Expectations")
books <- gutenberg_works(title %in% titles) %>%
gutenberg_download(meta_fields = "title")
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text,
regex("^chapter ",
ignore_case = TRUE)))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
by_chapter
library(tidyverse)
library(gutenbergr)
titles <- c("Twenty Thousand Leagues under the Sea",
"The War of the Worlds",
"Pride and Prejudice",
"Great Expectations")
books <- gutenberg_works(title %in% titles) %>%
gutenberg_download(meta_fields = "title")
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text,
regex("^chapter ",
ignore_case = TRUE)))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
by_chapter
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
install.packages("tidytext")
library(tidyverse)
library(tidytext)
library(gutenbergr)
full_text <- gutenberg_download(6522)
tidy_book <- full_text %>%
mutate(line = row_number()) %>%
unnest_tokens(word, text)
tidy_book
tidy_book %>%
sample_n(10) %>%
glimpse()
tidy_book %>%
countword, sort = TRUE)
tidy_book %>%
count(word, sort = TRUE)
get_stopwords()
anti_join(get_stopwords(source = "smart")) %>%
tidy_book %>%
count(word, sort = TRUE) %>%
coord_flip()
tidy_book %>%
anti_join(get_stopwords(source = "smart")) %>%
count(word, sort = TRUE) %>%
top_n(20) %>%
ggplot(aes(fct_reorder(word, n), n)) +
geom_col() +
coord_flip()
get_sentiments("bing")
tidy_book %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, sort = TRUE)
tidy_book %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment,word, sort = TRUE)
tidy_book %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n),
n,
fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
4
3
'hearth'
cool
'love'
'caijiemfrmj'
tidy_book %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n),
n,
fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
tidy_book %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n),
n,
fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
full_collection <- gutenberg_download(c(1272, 5614, 15076, 29185, 29186),
meta_fields = "title")
full_collection
book_words <- full_collection %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
book_words
book_tfidf <- book_words %>%
bind_tf_idf(word, title, n)
book_tfidf
book_tfidf %>%
arrange(-tf_idf)
group_by(title) %>%
book_tfidf %>%
top_n(10) %>%
ggplot(aes(fct_reorder(word, tf_idf), tf_idf, fill = title)) +
facet_wrap(~title, scales = "free")
group_by(title) %>%
book_tfidf %>%
top_n(10) %>%
ggplot(aes(fct_reorder(word, tf_idf), tf_idf, fill = title)) +
facet_wrap(~title, scales = "free")
book_tfidf %>%
group_by(title) %>%
top_n(10) %>%
ggplot(aes(fct_reorder(word, tf_idf), tf_idf, fill = title)) +
facet_wrap(~title, scales = "free")
tidy_ngram <- full_text %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
tidy_ngram
tidy_ngram %>%
count(bigram, sort = TRUE)
bigram_counts <- tidy_ngram %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE)
bigram_counts
View(book_words)
2+2
for i in [1,2,23,4]: print(i)
# polynomials
curve(3*x, xlim=c(-15, 15), ylim=c(-100, 100))
curve(x^2, col=2, add=T)
curve(x^3, col=3, add=T)
curve(x^4, col=4, add=T)
legend('top', legend=c('3x', 'x^2', 'x^3', 'x^4'), lty=1, col=1:4,
inset=c(0, -0.3), xpd=TRUE, ncol=4) # put legend outside plot
# powers and logarithms
a = 2
a^3 * a^2 # a^m * a^n = a^(m+n)
a^3 / a^2 # a^m / a^n = a^(m-n)
a^0 # a^0 = a^m / a^m = 1
a^(-2) # a^(-m) = a^0 / a^m = 1/a^m
(a^2)^3 # (a^m)^n = a^(m*n)
b = 8
b^{1/3} # n-th positive root of b is a such that a^n = b, if it exists
(b^(1/3))^3
4^(1/2) # is sqrt(4) - the principal square root of 4 (there are 2 roots: -2 and +2)
(-4)^(1/2) # sqrt(-4) does not exist
a^(3/4) # 4-th root of a^3
curve(2^x, xlim=c(-10,10))
curve(0.1^x, col=2, add=T)
exp(1) # euler number e, exp(a) = e^a
exp(3) # e^3
exp(1) # euler number e, exp(a) = e^a
exp(3) # e^3
curve(exp(x), xlim=c(-1,10))
k = 0:10
# approximation of Taylor series
g = Vectorize(function(x) sum(x^k/factorial(k))) # vectorize function over vector
curve( g, col=2, add=T)
k = 0:20 # better approximation
curve( g, col=3, add=T)
log(exp(3)) # log(a) = b such that e^b = a, for a >= 0
log(1)
curve(log(x), xlim=c(0, 10))
log(a*b) # log(a*b) = log(e^log(a)*e^log(b)) = log(e^(log(a)+log(b)) = log(a)+log(b)
log(a) + log(b)
log(a/b) # log(a/b) = log(e^log(a)/e^log(b)) = log(e^(log(a)-log(b)) = log(a)-log(b)
log(a) - log(b)
log(a^3, base=a) # log_a(b) = v such that a^v = b
log(a^3)/log(a) # a^log_a(b) = b = e^log(b) AND a^log_a(b) = e^(log(a)*log_a(b) ) IMPLY log(b)/log(a) = log_a(b)
log(a^3) # log(a^k) = k log(a)
3*log(a)
3*log(a)
3*log(a)
# powers and logarithms
a = 2
b = 8
b = 8
a^(-2) # a^(-m) = a^0 / a^m = 1/a^m
(a^2)^3
b = 8
b^{1/3}
b^{1/3} # n-th positive root of b is a such that a^n = b, if it exists
(b^(1/3))^3
log(a^3) # log(a^k) = k log(a)
3*log(a)
# linear functions
curve(3*x+2, ylim=c(-3,7)) # positive gradient (or slope)
curve(-3*x+3, col=2, add=T) # negative gradient (or slope)
curve(0*x + 2, col=3, add=T) # zero gradient - constant functions
# gradient of x^2
curve(x^2, xlim=c(-15, 15), ylim=c(-10, 100))
# tangent at x=a=5 has gradient 2*a and offset = a^2 - 2*a*a = -25
curve(10*x - 25, col=2, add=T)
for(a in -10:10) {
curve( 2*a*x + (a^2 - 2*a*a), col=3, add=T)
}
# derivatives
dx3 = D(expression(x^3), "x") # symbolic derivatives
dx3
class(dx3) # object type
eval(dx3, list(x=5)) # eval dx3 at x=5
dx3 = D(expression(x^3), "x")
dx3
class(dx3)
eval(dx3, list(x=5))
x = seq(-5, 5, 0.5)
# derivatives
dx3 = D(expression(x^3), "x")
dx3
ass(
class(dx3) # object type
class(dx3) # object type
eval(dx3, list(x=5)) # eval dx3 at x=5
eval
eval(dx3, list(x=5)) # eval dx3 at x=5
plot(x, eval(dx3), xlim=c(-5, 5))
fdx3 = function(x) eval(dx3) # eval dx3 at any x passed to function
curve(fdx3, from=-5, to=5)
D(dx3, "x") # second derivative
D(expression(x^n), "x") # partial derivative d x^n / dx
D(expression(x^n), "n") # partial derivative d x^n / dn
# gradient of f(x) using f'(x)
f = function(x) x^4 # replace body with any expression on x, eg. x^3
fprime = function(x) eval(D(body(f), "x"))
root = uniroot(fprime, c(-1,1))$root
root = uniroot(fprime, c(-1,1))$root
root
root
root
fprime(root)
fsecond = function(x) eval(D(D(body(f), "x"), "x"))
fsecond(root)
# minimum using numeric methods
optimize(f, c(-1000, 1000))
# definite integrals computed using numeric methods (with approximation)
ee = function(x, lambda=2) x*lambda*exp(-lambda*x)
integrate(ee, 0, Inf) # Expectation of exponential distribution: 1/lambda
# area between -z and z where z = .95 quantile
curve(dnorm, xlim=c(-2, 2))
integrate(dnorm, -Inf, Inf)
z = 1.644854 # qnorm(.95)
segments(z, 0, z, dnorm(z), col=2)
segments(-z, 0, -z, dnorm(-z), col=2)
integrate(dnorm, -z, z)
# from discrete Uniform to Uniform
m = 18; M = 30
x = m:(M-1) # M is excluded, so that we have M-m points
pmf = table(x)/length(x)
plot(pmf, type='p', ylim=c(0, .1), xlim=c(m-1, M+1)) # uniform discrete pmf
pmf
1/(M-m) # df in [m, M]
curve(dunif(x, m, M), add=T, col=2) # uniform pdf
dunif(seq(m, M, 0.1), m, M) # density function
curve(punif(x, m, M), xlim=c(m-1, M+1)) # uniform cdf
# from Geom to Exp
p = 0.75 # unfair coin
k = 1:10
plot(k, dgeom(k-1, p)) # ATTENTION: k-1 and not k
plot(k-1/2, dgeom(k-1, p)) # center at k-1/2
lambda = log(1/(1-p))
curve( dexp(x, lambda), add=T, col=2) # exponential pdf
plot(k-1/2, dgeom(k-1, p), log="y") # y log-scale
curve( dexp(x, lambda), add=T, col=2) # exponential pdf
curve( pexp(x, lambda), xlim=c(0,10)) # exponential cdf
# from Bin to Norm
p = 0.5 # fair coin
n = 20 # number of trials
k = 0:n # sum of successes
plot(k, dbinom(k, n, p), pch=16, xlim=c(-1, n+1)) # dbinom R function for pmf
mu = n*p; sigma = sqrt(n*p*(1-p)) # normal approximation of the binomial
curve(dnorm(x, mu, sigma), add=T, col=2)
help(dnorm) # ATTENTION: N(mu, sigma), and not N(mu, sigma^2)
curve(pnorm(x), xlim=c(-5,5)) # standard normal cdf
# quantiles
curve( pexp(x, lambda), xlim=c(0,10)) # exponential pdf
qexp(.95, lambda) # .95 quantile
curve( qexp(x, lambda), xlim=c(0,1)) # exponential quantiles
curve( log(1/(1-x))/lambda, add=T, col="red") # closed form for quantiles
# quantiles
curve( pexp(x, lambda), xlim=c(0,10)) # exponential pdf
qexp(.95, lambda) # .95 quantile
curve( qexp(x, lambda), xlim=c(0,1)) # exponential quantiles
curve( log(1/(1-x))/lambda, add=T, col="red") # closed form for quantiles
plot(k, pgeom(k-1, p)) # pgeom R function for cdf
qgeom(.95, p) # .95 quantile
curve( qgeom(x, p), xlim=c(0,1)) # quantiles apply to discrete distributions as well
runif(5, 0, 1) # 5 random numbers ~ U(0,1)
runif(5, 0, 1)
set.seed(0) # set seed in random number generation
runif(5, 0, 1)
set.seed(0)
runif(5, 0, 1)
# realizations ~ U(0,1)
ru = runif(10000, 0, 1)
# from Unif to Ber
u2ber = function(nr, p) {
ru = runif(nr)
rb = as.integer(ru < p)
return(rb)
}
rb = u2ber(10000, 0.75)
pmf = table(rb)/length(rb)
plot(pmf, type='p')
# from Ber to Binom
# from Unif to Ber
ber2bin = function(nr, n, p) {
rbi = rep(0, nr)
for(i in 1:n) {
rbi = rbi + u2ber(nr, p)
}
return(rbi)
}
n = 10
p = 0.5
rbi = ber2bin(10000, n, p)
pmf = table(rbi)/length(rbi)
plot(pmf, type='p')
points(0:n, dbinom(0:n, n, p), col=2)
# from Unif to Exp
lambda = 2
re = 1/lambda * log(1/(1-ru)) # explicit transformation
plot(ecdf(re))
curve(pexp(x,lambda), col=2, add=T) # theoretical CDF
hist(re, breaks=60, freq=FALSE) # histogram of re
curve(dexp(x,lambda), col=2, add=T, lwd=3) # theoretical DF
runif(5, 0, 1) # 5 random numbers ~ U(0,1)
runif(5, 0, 1)
set.seed(0) # set seed in random number generation
runif(5, 0, 1)
set.seed(0)
runif(5, 0, 1)
# realizations ~ U(0,1)
ru = runif(10000, 0, 1)
# from Unif to Ber
u2ber = function(nr, p) {
ru = runif(nr)
rb = as.integer(ru < p)
return(rb)
}
rb = u2ber(10000, 0.75)
pmf = table(rb)/length(rb)
plot(pmf, type='p')
# from Ber to Binom
# from Unif to Ber
ber2bin = function(nr, n, p) {
rbi = rep(0, nr)
for(i in 1:n) {
rbi = rbi + u2ber(nr, p)
}
return(rbi)
}
n = 10
p = 0.5
rbi = ber2bin(10000, n, p)
pmf = table(rbi)/length(rbi)
plot(pmf, type='p')
points(0:n, dbinom(0:n, n, p), col=2)
# from Unif to Exp
lambda = 2
re = 1/lambda * log(1/(1-ru)) # explicit transformation
plot(ecdf(re))
curve(pexp(x,lambda), col=2, add=T) # theoretical CDF
hist(re, breaks=60, freq=FALSE) # histogram of re
curve(dexp(x,lambda), col=2, add=T, lwd=3) # theoretical DF
# clean all
rm(list=ls())
# SET WORKING DIR FOR OUTPUT PDFs AND INPUT DATASETS (../../data)
setwd("C:/Users/Salvatore Ruggieri/Desktop/tmp")
# install packages
#install.packages("ISwR") # just once
library(ISwR) # attach (load) package
search() # attached packages (in RStudio/environment)
# Reticulate: calling Python from R
# https://rstudio.github.io/reticulate/
# install.packages("reticulate")
library(reticulate)
par(mar=c(4,4,1,1))
# discrete data: rolling a die 1000 times
dataset = sample(1:6,1000,replace=T)
barplot(table(dataset)) # absolute
barplot(prop.table(table(dataset))) # relative
plot(as.factor(dataset)) # barplot is default for factors data types
# continuous data: sampling from normal distribution 1000 times
dataset = rnorm(100)
barplot(table(dataset)) # does not work: why?
hist(dataset)
hist(dataset, freq=FALSE) # scaled to total area of 1
hist(dataset, freq=FALSE, breaks=20) # number of bins
hist(dataset, freq=FALSE, breaks=6)
hist(dataset, freq=FALSE, breaks=seq(-3, 3, 0.5)) # bin width
curve(dnorm(x), add=T, col="red", lwd=2) # generating density
# clean all
rm(list=ls())
# working dir
wdir = "C:\Users\carlo\Desktop\Università\data science and business informatics\statistical methods\project\data"
setwd(wdir)
# to reload the whole dataset at once, run
load(file="aida.RData")
View(aida)
# working dir
wdir = "C:\Users\carlo\Desktop\Università\data science and business informatics\statistical methods\project\data\"
# to reload the whole dataset at once, run
load(file="aida.RData")
View(aida)
# summaries
table(aida$`Registered office address - Region`)
table(aida$`Legal status`)
table(aida$`Legal form`)
# working dir
wdir = r"C:\Users\carlo\Desktop\Università\data science and business informatics\statistical methods\project\data\"
# to reload the whole dataset at once, run
load(file="aida.RData")
View(aida)
# summaries
table(aida$`Registered office address - Region`)
table(aida$`Legal status`)
table(aida$`Legal form`)
# working dir
wdir = "C:\Users\carlo\Desktop\Università\data science and business informatics\statistical methods\project\data\"
# to reload the whole dataset at once, run
load(file="aida.RData")
View(aida)
# summaries
table(aida$`Registered office address - Region`)
table(aida$`Legal status`)
table(aida$`Legal form`)
# working dir
wdir = "C:/Users/carlo/Desktop/Università/data science and business informatics/statistical methods/project/data/"
# to reload the whole dataset at once, run
load(file="aida.RData")
View(aida)
load("C:/Users/carlo/Desktop/Università/data science and business informatics/statistical methods/project/data/aida.RData")
# to reload the whole dataset at once, run
load(file="aida.RData")
View(aida)
# working dir
wdir = "C:/Users/carlo/Desktop/Università/data science and business informatics/statistical methods/project/data/"
# to reload the whole dataset at once, run
load(file="aida.RData")
View(aida)
# summaries
table(aida$`Registered office address - Region`)
# summaries
table(aida$`Registered office address - Region`)
table(aida$`Legal status`)
# to reload the whole dataset at once, run
load(file="aida.RData")
View(aida)
# working dir
wdir = "C:/Users/carlo/Desktop/Università/data science and business informatics/statistical methods/project/data/"
setwd(wdir)
load(file="aida.RData")
View(aida)
